<?xml version="1.0" encoding="utf-8"?>
<search>
  
  
  
  <entry>
    <title>CMU15-445 Proj4.Concurrency Control</title>
    <link href="/2024/10/05/Proj4.Concurrency%20Control/"/>
    <url>/2024/10/05/Proj4.Concurrency%20Control/</url>
    
    <content type="html"><![CDATA[<h1 id="Overview"><a href="#Overview" class="headerlink" title="Overview"></a>Overview</h1><p>23fall bustub最后proj <strong>concurrency control</strong> 不同于之前的lock manager,cxs为我们贡献了更为有趣的<strong>mvcc</strong>多版本控制并发.<br>依赖于所有之前实现的bpm,index,query executor,并且要对几个执行器进行重写以支持mvcc,最后我们可以得到支持<strong>Snapshot Isolation</strong>级别的事务管理</p><h1 id="Task1-timestamps"><a href="#Task1-timestamps" class="headerlink" title="Task1 timestamps"></a>Task1 timestamps</h1><p>为了管理事务，我们给予事务两个<code>timestamp</code>:<code>read_ts</code> 和<code>commit_ts</code>，其中<code>read_ts</code>决定了该事务能读到的数据。<code>commit_ts</code>指定了该事务提交后所更改元组的<code>timestamp</code>。举个例子：<br><img src="/../images/41.png"></p><p>如果我们有一个<code>read_ts</code> &#x3D; 3的事务，它将在本例中看到 A3、 B3、 C2和 D3。如果读取时间戳 &#x3D; 2，它将看到 A2，B1，C2。当事务开始时，<strong>读取时间戳将是最新提交的事务的时间戳</strong>，这样事务就能够在事务开始之前看到所有提交的内容。当事务提交时，它会被分配一个比<code>last_commit_ts</code>大1的提交时间戳。在bustub中默认<code>last_commit_ts = 1</code>，因此第一个事务将会被分配<code>read_ts = 1</code>，当其提交时<code>commit_ts = 2</code></p><h3 id="task1-1-Timestamp-Allocation"><a href="#task1-1-Timestamp-Allocation" class="headerlink" title="task1.1 Timestamp Allocation"></a>task1.1 Timestamp Allocation</h3><p>对于task1.1，只需完成<code>read_ts</code>和<code>commit_ts</code>的分配即可.</p><h3 id="task1-2-Watermark"><a href="#task1-2-Watermark" class="headerlink" title="task1.2 Watermark"></a>task1.2 Watermark</h3><p><code>Watermark</code>是所有正在进行的事务中<strong>最低的读取时间戳</strong>。我们将维护两个函数:<code>Watermark::AddTxn</code> 和 <code>Watermark::RemoveTxn</code>，在加入事务、删除事务的时候更新<code>watermark</code><br>watermark中<code>commit_ts</code>记录了上一个<code>commit_ts</code>，也就是<code>txn_mng中的last_commit_ts</code>。<br>在bustub提供的代码中，对于current_reads_使用了<code>unorderd_map</code>来维护，修改成std::map可以方便地完成。</p><h1 id="Task2-Storage-Format-and-Sequential-Scan"><a href="#Task2-Storage-Format-and-Sequential-Scan" class="headerlink" title="Task2 Storage Format and Sequential Scan"></a>Task2 Storage Format and Sequential Scan</h1><p>对于元组的多版本控制，我们使用<strong>delta表</strong>来实现，只记录修改的值，每个元组都有一个versionlink，并通过versionlink-&gt;undolink-&gt;undolog的形式存储。其值的变化(包括delete)都会反映在undolog中。</p><h3 id="2-1-Tuple-Reconstruction"><a href="#2-1-Tuple-Reconstruction" class="headerlink" title="2.1 Tuple Reconstruction"></a>2.1 Tuple Reconstruction</h3><p>功能清晰明了，遍历<code>undo log</code>并根据其中的信息还原，像图片展示地一样：<br><img src="/../images/42.png"></p><p>需要注意的是<code>undo log</code>的结构：<br><img src="/../images/43.png"><br><code>undo log</code>结构存的<code>Tuple</code>只含有修改的<code>column</code>，而<code>ReconstructTuple</code>函数参数中未给予这个<code>undolog.tuple.schema</code>，这意味着我们无法简单地索引这个<code>Tuple</code>的值，像官方文档中说的：</p><blockquote><p>you will likely need to construct the partial schema of the tuple based on the table schema and the modified fields.</p></blockquote><p>因此我们需要自己写一个helpfunc:GetUndoLogSchema。就可以对<code>undolog.tuple.GetValue</code>获取值。(注意这里的col_idx和原始元组是不一样的)</p><h3 id="2-2-Sequential-Scan-Tuple-Retrieval"><a href="#2-2-Sequential-Scan-Tuple-Retrieval" class="headerlink" title="2.2 Sequential Scan &#x2F; Tuple Retrieval"></a>2.2 Sequential Scan &#x2F; Tuple Retrieval</h3><p>重写seq执行器使事务读到它<strong>应该</strong>读到的数据，我们需要比较事务的<code>read_ts</code>和<code>tuple_ts</code>，如果需要重构元组，还要比较<code>undolog</code>中记录的<code>ts</code>。<br>这里引入<strong>临时时间戳</strong>：事务在更改元组时会先给元组上临时时间戳 &#x3D; <strong>当前事务id</strong> + <code>txn_start_id</code>(一个很大的值，为了与commit_ts区别开)。注意这里<strong>当前事务id</strong>指的是可阅读的，而并非代码中记录的<code>GetTransactionId()</code>,实际上当前事务的临时时间戳 &#x3D; <code>GetTransactionId()</code>。在事务提交时，才会给元组记录上commit_ts.<br>具体来说：</p><ol><li>当前事务<code>read_ts</code> &gt;<code>tuple_ts</code>或者<code>tuple_ts</code> &#x3D; <code>txn_id</code>(很大的不可阅读的值)，前者代表当前事务newer，后者代表是事务自修改(insert or delete or update). 这都意味着可以直接使用元组</li><li>在不满足上述的条件下，需要reconstruct tuple，我们遍历undolog找到能使用的最新的undolog，并保存从尾部到最新的undolog串以reconstruct元组。</li><li>对于其他情况，<code>++(iter_)</code>跳过即可。</li></ol><h1 id="Task3-MVCC-Executors"><a href="#Task3-MVCC-Executors" class="headerlink" title="Task3 MVCC Executors"></a>Task3 MVCC Executors</h1><h3 id="3-1-insert"><a href="#3-1-insert" class="headerlink" title="3.1 insert"></a>3.1 insert</h3><p>修改插入算子，根据文档描述：</p><ol><li>The timestamp in the table heap should be set to the transaction temporary timestamp. 意思是将元组meta中的<code>ts</code>设为<code>transaction temporary timestamp</code>，即<figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs cpp">exec_ctx_-&gt;<span class="hljs-built_in">GetTransaction</span>()-&gt;<span class="hljs-built_in">GetTransactionId</span>();<br></code></pre></td></tr></table></figure></li><li>the next version link of this tuple should be <code>nullopt</code>. 我们使用bustub提供给的函数,调用<figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs cpp">txn_mng-&gt;<span class="hljs-built_in">UpdateVersionLink</span>(*rid, std::<span class="hljs-literal">nullopt</span>, <span class="hljs-literal">nullptr</span>);<br></code></pre></td></tr></table></figure></li><li>You should also add the RID to the write set. btw这里write set写集是 <strong>事务在其执行过程中产生的所有写操作的集合</strong>(maybe 课上讲到过 但我是第一次见)，就是说我们需要在修改数据库的过程中维护这个write set。对于这里，只需调用<figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs cpp">exec_ctx_-&gt;<span class="hljs-built_in">GetTransaction</span>()-&gt;<span class="hljs-built_in">AppendWriteSet</span>(table_info_-&gt;oid_, *rid);<br></code></pre></td></tr></table></figure></li></ol><h3 id="3-2-Commit"><a href="#3-2-Commit" class="headerlink" title="3.2 Commit"></a>3.2 Commit</h3><p>文档中的<strong>5</strong>个步骤非常详细，并且在框架代码中，commit已经大部分实现。我们大概需完成<strong>第二步</strong>和<strong>第三步</strong><br>2. 获取事务预备的<code>commit_ts</code>，选择框架代码中欲维护的<code>last_commit_ts + 1</code>即可。<br>3. 遍历写集，调用<code>tableheap</code>的<code>UpdateTupleMeta</code>函数即可。</p><h3 id="3-3-Update-and-Delete-Executor"><a href="#3-3-Update-and-Delete-Executor" class="headerlink" title="3.3 Update and Delete Executor"></a>3.3 Update and Delete Executor</h3><p>检测<strong>写-写冲突</strong>：</p><ol><li>元组被未提交的事务修改。</li><li>元组被已提交的事务修改，但自身<code>read_ts</code> &lt; 提交txn的<code>commit_ts</code>，意味着我们正在修改<code>未来</code>的元组。<br>在这两种情况下很容易发生丢失更新、读脏数据等冲突，需要做的是：<br>将事务状态设置为 <code>TAINTED</code>，并且需要抛出 <code>ExectionException</code> 以标记 SQL 语句未能执行(此处不需要处理abort逻辑)</li></ol><p>我们可以在检测之前检查是否是自修改(self-modification)，若是自修改则不用检测该冲突。</p><p>这里注意，由于我们要实现复杂的事务操作和后面的并发，不同于p3，需要以<code>pipline breaker</code>的方式实现执行器(如p3中实现的agg、hash)。在init阶段读取元组到缓冲区中。</p><p>在完成自修改判断和写写检测后，会有这些情况：</p><ol><li>自修改：<ol><li>对于delete，直接修改<code>tuplemeta</code>标记<code>is_delete</code>标志位即可(这里有一个对于undolog里delete标志位的思考，它是简单的标志元组被删除吗？对于delete，我们只修改<code>is_delete</code>，而tuple的信息还保存着，真的需要再生成一个undolog吗？实际上通篇写完后，发现这个标志位怎么理解都可以，具体看自己的实现和维护，后面task4.1再讲讲)</li><li>对于update，建议大家认真看文档中关于自修改的example，实际上这里也分两种情况:<ol><li>对于此前自修改过的位，比如原来是(A,3)，第一次修改(A,4)，这次自修改(A,5)，这意味着这次修改<strong>不改变undolog</strong>，只是更新了table_heap，也意味着自修改过程中上次的修改作废，换句话说(A,4)这次更新不需要记录，<strong>就像他没存在过一样</strong>.</li><li>对于此前没修改过的，比如从(A,3)到(A,5)到(B,5)，我们需要记录原本元组A的值，生成新的undolog。</li></ol></li></ol></li><li>非自修改：<ol><li>对于删除，生成包含原始元组完整数据的<code>undolog</code>。</li><li>对于更新，需要对比生成undolog。<br>生成undolog后将其链入元组的versionlink中，对于自修改，我们不需要再链一个新的undolog，只需调用：<figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs cpp">exec_ctx_-&gt;<span class="hljs-built_in">GetTransaction</span>()-&gt;ModifyUndoLog<br></code></pre></td></tr></table></figure>对于非自修改，则需要插入新的undolog，调用：<figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs cpp"><span class="hljs-keyword">auto</span> new_link = exec_ctx_-&gt;<span class="hljs-built_in">GetTransaction</span>()&gt;<span class="hljs-built_in">AppendUndoLog</span>(new_undolog);<br>txn_manager-&gt;UpdateUndoLink<br></code></pre></td></tr></table></figure></li></ol></li></ol><p>最后不要忘了update tableheap and writeset。<br>这块应该会有比较长的debug时间，包括边缘情况的处理和逻辑的实现缺陷，大家一定要写好<code>TxnMgrDbg</code>这个debug函数来节约自己的时间和提高效率。</p><h3 id="3-4-Stop-the-world-Garbage-Collection"><a href="#3-4-Stop-the-world-Garbage-Collection" class="headerlink" title="3.4 Stop-the-world Garbage Collection"></a>3.4 Stop-the-world Garbage Collection</h3><p>删除那些我们永远不会读到的数据，而<code>garbage</code>靠什么来界定呢？记得我们在task1写的<code>watermark</code>,它是最小的read_ts，试想，如果一个undolog的ts小于<code>watermark</code>，我们可能就永远不会读到它(特殊情况是，table_heap上的tuple我们无法读取，必须从其undolog来重构元组，这种情况下，即使undolog的ts小，我们仍然需要保留。具体可见example图，十分清晰)</p><p>实现来说，我们需要遍历table heap和tuple的undolog,记录下需要保留的txn_id,注意,我们只能collect那些<code>abort</code>或者<code>commited</code> status的txn。</p><p>此时，您应该通过<em>TxnExecutorTest</em>。</p><h1 id="Task-4-Primary-Key-Index"><a href="#Task-4-Primary-Key-Index" class="headerlink" title="Task 4 - Primary Key Index"></a>Task 4 - Primary Key Index</h1><p>这个task开始，我们需要处理主键索引的情况。</p><h3 id="4-1-Inserts"><a href="#4-1-Inserts" class="headerlink" title="4.1 Inserts"></a>4.1 Inserts</h3><p>文档写的非常详细，简单来说：</p><ol><li>插入前，检查元组是否已经在索引中，如果是，<code>SetTainted and throw ExecutionException</code></li><li>在inserttuple到insertindex这段间，由于并发，可能<strong>txn2</strong>正要<code>insertindex</code>时，<strong>txn1</strong>通过了第一步的检查并且已经将元组插入到<code>table_heap</code>中，此时<strong>txn2</strong>已经<code>insertindex</code>完成，而<strong>txn1</strong>正想要<code>insertindex</code>，当然主键约束不允许再次插入索引，此时<strong>txn1</strong>应该<code>SetTainted and throw ExecutionException</code>.<br>实现完成后，可以通过insert的并发测试.</li></ol><h3 id="4-2-Index-Scan-Deletes-and-Updates"><a href="#4-2-Index-Scan-Deletes-and-Updates" class="headerlink" title="4.2 Index Scan, Deletes and Updates"></a>4.2 Index Scan, Deletes and Updates</h3><p>(这块内容太多了，由于是写完再总结，可能会遗漏很多细节，如果帮不到读者请见谅.)<br>一旦在索引中创建了一个条目，它将总是指向相同的 RID，即使元组被标记为删除，也不会被删除，这样以前的事务仍然可以通indexscan访问之前的版本。</p><h4 id="Indexscan"><a href="#Indexscan" class="headerlink" title="Indexscan"></a>Indexscan</h4><p>重写<code>indexscan</code>使之支持<code>mvcc</code>,把之前<code>seq_scan</code>有关<strong>重组元组</strong>的内容copy过来即可。</p><h4 id="Insert-Deletes-and-Updates"><a href="#Insert-Deletes-and-Updates" class="headerlink" title="Insert,Deletes and Updates"></a>Insert,Deletes and Updates</h4><h5 id="in-progress"><a href="#in-progress" class="headerlink" title="in_progress"></a>in_progress</h5><p>这里需要实现并发控制(cc),bustub为我们提供<code>versionlink</code>中字段<code>in_progress</code>来控制，当其被设置成true,意味着有线程在更新元组和版本链，其他线程不应该修改该元组。很像锁对吧，<br>很容易想到，我们想要线程安全的流程大概是这样：</p><ol><li>检查<code>in_progress</code>是否为false，如果是设置其为true.</li><li>更新元组，包括其versionlink 、table_heap and writeset.</li><li>设置<code>in_progress</code>为false.<br>但是注意这并不是一个原子量，这意味着访问这个量时也会存在各种各样的数据竞争，这就是这里的痛点。在第一步中，我们实现的步骤大概是，获取versionlink，设置标志位，更新<code>versionlink</code>。注意到<code>Updateversionlink</code>函数中有一个check函数，这也就是我们检查当前元组versionlink的in_progress是否可以被获取。要检查的内容大致有两项：<ol><li>在获取versionlink到试图修改versionlink的过程中，versionlink的值是否被改变了.</li><li>in_progress是否为false.</li></ol></li></ol><p>我们可以写一个lambda check函数捕获在修改前get的versionlink.在<code>Updateversionlink</code>函数内部会根据rid再获取一次<code>versionlink</code>，比较的就是这两个版本。<br>当<code>Updateversionlink</code>返回true时，就代表我们设置<code>in_progress</code>为true成功，即拿到了当前元组的锁。之后就可放心地跑逻辑。<br>关于释放<code>in_progress</code>的时机，一个简单的实现是在事务<code>commit</code>时根据<code>writeset</code>，将修改元组的<code>versionlink</code>的<code>in_progress</code>全部释放，这样做的好处是，所有自修改的逻辑运行不需要拿取<code>in_progress</code>，因为上一个修改的事务已经控制<code>in_progress</code>且未释放。<br>因此，并发控制中，要加入执行器的逻辑是，在非自修改getversionlink后，去尝试获取<code>in_progress</code>,当然也不要忘了<strong>写写冲突</strong>。<br><strong>tips</strong>:在控制<code>in_progress</code>后需重新<code>gettuple</code>，因为之前根据pipline breaker生成的缓冲区元组可能已经是过时的。</p><h5 id="insert"><a href="#insert" class="headerlink" title="insert"></a>insert</h5><p>修改<code>insert</code>，主要是两个点：</p><ol><li>在task4.1中，insert的第一个检查即是检查元组是否存在索引中，此时我们不应该<code>abort</code>该事务，而是像<code>update</code>一样去修改这个被删除的元组，根据自修改和非自修改生成undolog维护该tuple的versionlink.这里就提到了我在前面讲的关于<code>undolog</code>中<code>delete</code>标志位的设置。在我的实现中，我仅会在这种情况下，也就是在索引条件下插入到由<code>delete</code>执行器删除的元组中，并且是非自修改的情况下，设置<code>undolog is_delete = true</code>.因为此时才需要从<code>undolog</code>中找寻<strong>被delete过</strong>的信息.</li><li>边缘情况，想想我们的并发控制，是根据Tuple的versionlink的in_progress标志位来做锁，那如果一个元组还没有versionlink，该怎么办？例如，txn1 将一个元组插入并提交到表堆中，而 txn2想删除它。在这种情况下，insert需要先为创建一个版本链接，设置<code>undolog</code>为<code>invalid</code>，并将<code>in_progress</code> 设置为 <code>true</code>。可是调用<code>Updateversionlink</code>的前提是该元组已经插入到table_heap中并且有了rid。因此我们必须在<code>inserttuple</code>后得到一个rid，再调用这个函数。这当然就有了timing，会发生数据竞争。我的处理方式是在insert前锁上versionlink:<figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs cpp"><span class="hljs-function">std::unique_lock&lt;std::shared_mutex&gt; <span class="hljs-title">lck</span><span class="hljs-params">(txn_mng-&gt;version_info_mutex_)</span></span>;<br></code></pre></td></tr></table></figure>再调用一个套壳的<code>Updateversionlink</code>(把第一行锁获取删掉),之后注意unlock该锁。</li></ol><h5 id="delete-and-update"><a href="#delete-and-update" class="headerlink" title="delete and update"></a>delete and update</h5><p>对于数据操作的逻辑不需要做什么修改，在非自修改时注意获取<code>in_progress</code>，并且注意获取最新的元组信息即可。</p><h3 id="4-3-Primary-Key-Updates"><a href="#4-3-Primary-Key-Updates" class="headerlink" title="4.3 Primary Key Updates"></a>4.3 Primary Key Updates</h3><p>对于主键的update，因为可能占到别的元组位置导致唯一性冲突，解决方法是把之前的key元组全部删除再插入新的元组。即修改update执行器逻辑，当检测到要更新主键元素时，先调用delete执行器的修改逻辑，再调用insert执行器的修改逻辑即可。<br>要获取update更新的列，可以从<code>plan_-&gt;target_expressions_</code>入手.</p><h1 id="End"><a href="#End" class="headerlink" title="End"></a>End</h1><p>写的时间跨度有点大了,只能讲讲宏观上的理解了,最后并发debug的过程也没有记录下,很多细节都没记录上,记录的习惯还是太差了:( btw感谢CMU,感谢Alan,感谢cxs让我们能有机会接触如此棒的课程!</p><p>最后附上通过截图：<br><img src="/../images/44.png"></p><p>参考文章：<br><a href="https://zhuanlan.zhihu.com/p/679864449">CMU15-445 2023 Fall Project#4 - Concurrency Control</a><br><a href="https://zhuanlan.zhihu.com/p/713107182">CMU15445 (Fall 2023) Project 4 - Concurrency Control 思路分享</a></p>]]></content>
    
    
    
  </entry>
  
  
  
  <entry>
    <title>CMU15-445 Proj3.Query Execution</title>
    <link href="/2024/04/22/Proj3.Query%20Execution/"/>
    <url>/2024/04/22/Proj3.Query%20Execution/</url>
    
    <content type="html"><![CDATA[<p>项目的任务是写些算子和完成一些优化，刚开始动手写时会感到异常困难，但在完成之后回过头来看代码，又会觉得没什么难度。笔者也是从难以下手，一行写不出来的状态到完成了整个项目，因此，在你感到困难的时候，不要害怕，读一读sample executors(projection、filter、values)，读一读几个头文件，跑一跑explain，相信会有收获。</p><p>BusTub 使用迭代器(即 Volcano🌋模型)查询处理模型，其中每个执行器实现一个 Next 函数以获得下一个 tuple 结果，除了返回元组外，Next函数还返回一个记录标识符(RID)。记录标识符作为元组的唯一标识符。算子执行方向是Top-to-Bottom. 从根节点算子开始，不断地 pull 下层算子的数据。</p><p>BusTub依赖于前几个proj的实现，我们需要用到自己的bpm存储，在建立index时要用到自己的hash index.</p><h1 id="Task-1-Access-Method-Executors"><a href="#Task-1-Access-Method-Executors" class="headerlink" title="Task 1 - Access Method Executors"></a>Task 1 - Access Method Executors</h1><p>在开始前，我们先通过知乎大佬画的图了解一下存储结构。<br><img src="/../images/31.png"><br>层层递进，展示了如何获取Tuple的过程。</p><h2 id="SeqScan"><a href="#SeqScan" class="headerlink" title="SeqScan"></a>SeqScan</h2><p>顺序扫描，即按顺序下去输出一个个tuple，注意到hint，Bustub为我们准备了<code>TableIterator</code>对象，因此我们需要找到<code>Table</code>对象，再调用<code>table-&gt;MakeIterator()</code>得到迭代器。这里会有一个指针的使用，建议使用<strong>智能指针</strong>以简化内存控制。至此这个算子基本完成了，再根据hint完善一些细节。</p><h2 id="Insert-Delete-Update"><a href="#Insert-Delete-Update" class="headerlink" title="Insert Delete Update"></a>Insert Delete Update</h2><p>三个相似的算子，hint写的很完善，主要操作逻辑已有现有函数可使用，注意next函数返回受影响的行数，操作时需要更新表的索引，这个过程需要先调用<code>tuple-&gt;keyFromtuple</code>，再根据生成的<strong>keytuple</strong>进行<code>insertEntry</code> or <code>deleteEntry</code></p><h2 id="IndexScan"><a href="#IndexScan" class="headerlink" title="IndexScan"></a>IndexScan</h2><p>对于有谓词的seq_scan查询，可以根据索引进行点查找，根据hint，索引对象是</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs cpp">htable_ = <span class="hljs-built_in">dynamic_cast</span>&lt;HashTableIndexForTwoIntegerColumn *&gt;(index_info_-&gt;index_.<span class="hljs-built_in">get</span>())<br></code></pre></td></tr></table></figure><p>我们提取出谓词右边的值，比如v1&#x3D;40，提出40建立元组，再根据<code>htable_-&gt;Scankey</code>得到结果元组。</p><h2 id="Optimizing-SeqScan-to-IndexScan"><a href="#Optimizing-SeqScan-to-IndexScan" class="headerlink" title="Optimizing SeqScan to IndexScan"></a>Optimizing SeqScan to IndexScan</h2><p>上面提到，indexscan是seqscan有filter时的优化，在这我们就来实现这个：</p><ol><li>第一步谓词下移到seqscan，这里可以参考<strong>filter</strong>算子的实现，可以看到如何判断谓词，依样画葫芦即可</li><li>第二步优化成<code>indexscanplannode</code>，这里参考其他optimizer的写法，整体结构是一样的，注意到这里只要求单谓词有索引优化即可。对于索引列和谓词列可以这么来检查：<figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs cpp"><span class="hljs-keyword">auto</span> filter_index_col = <span class="hljs-string">&quot;#0.&quot;</span> + std::<span class="hljs-built_in">to_string</span>(index_col);<br><span class="hljs-keyword">if</span> (filter_index_col == seq_scan_plan.filter_predicate_-&gt;children_[<span class="hljs-number">0</span>]-&gt;<span class="hljs-built_in">ToString</span>())<br></code></pre></td></tr></table></figure></li></ol><p>至此可以完成SQLLogicTests #1 to #6 的测试。</p><h1 id="Task2-Aggregation-Join-Executors"><a href="#Task2-Aggregation-Join-Executors" class="headerlink" title="Task2 Aggregation &amp; Join Executors"></a>Task2 Aggregation &amp; Join Executors</h1><h2 id="Aggregation"><a href="#Aggregation" class="headerlink" title="Aggregation"></a>Aggregation</h2><p>聚合的过程中，我们需要保存之前聚合的信息，这通常是用哈希表实现的，通过hint得到bustub为我们实现了<code>SimpleAggregationHashTable</code>。<br>我们首先需要为这个类实现<code>CombineAggregateValues</code>函数，功能是对聚合值的计算。其中，对于<code>AggregateValue</code>，如果它本身是<code>x_null</code>，进行<strong>Add</strong>等运算时结果始终是null，因此需要if判断一下。阅读其他的代码，会发现<code>InsertCombine</code>这个函数。我们就是它完成对聚合的计算、存储。</p><p>注意到hint写到,agg算子是<strong>pipeline breakers</strong>，根据上述对哈希表建立的理解，很容易想到是在init中完成对聚合的所有计算。在next中利用<code>SimpleAggregationHashTable::Iterator</code>对结果进行迭代输出。</p><p>测试中有这么一个查询：</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs sql"><span class="hljs-keyword">select</span> v5, <span class="hljs-built_in">min</span>(v1), <span class="hljs-built_in">sum</span>(v2), <span class="hljs-built_in">count</span>(<span class="hljs-operator">*</span>) <span class="hljs-keyword">from</span> t1 <span class="hljs-keyword">group</span> <span class="hljs-keyword">by</span> v5; <span class="hljs-comment">-- no groups, no output</span><br></code></pre></td></tr></table></figure><p>注意<strong>no groups, no output</strong>.</p><h2 id="Nestedloopjoin"><a href="#Nestedloopjoin" class="headerlink" title="Nestedloopjoin"></a>Nestedloopjoin</h2><p>要求实现<strong>inner join</strong> and <strong>left join</strong><br>区别在于<strong>inner join</strong>需要满足谓词，而<strong>left join</strong>在不满足的情况下需要填充null值。<br>基本思想如其名，嵌套循环，对于每一个<strong>left tuple</strong>,遍历<strong>right tuple</strong>得到结果。</p><h1 id="Task3-HashJoin-Executor-and-Optimization"><a href="#Task3-HashJoin-Executor-and-Optimization" class="headerlink" title="Task3 - HashJoin Executor and Optimization"></a>Task3 - HashJoin Executor and Optimization</h1><h2 id="HashJoin"><a href="#HashJoin" class="headerlink" title="HashJoin"></a>HashJoin</h2><p>当有连接需求且包含等价条件时，我们可以先计算等价条件，再将满足条件的左右元组连接起来，而避免nestedloop的复杂。由于我们要实现left join，因此我们先遍历<strong>right tuples</strong>建立哈希表：</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs cpp">std::unordered_map&lt;AggregateKey, std::vector&lt;Tuple&gt;&gt; hash_table_;<br></code></pre></td></tr></table></figure><p>阅读hint，此算子同样是一个<strong>pipeline breakers</strong>，我们需要在init中完成对哈希表的建立。而后在next函数中对left tuples计算等价条件，去哈希表里寻找是否有匹配的元组。获取输出的过程和Nestedloopjoin算子相似。</p><h2 id="Optimizing-NestedLoopJoin-to-HashJoin"><a href="#Optimizing-NestedLoopJoin-to-HashJoin" class="headerlink" title="Optimizing NestedLoopJoin to HashJoin"></a>Optimizing NestedLoopJoin to HashJoin</h2><p>对上述算子写优化器，要做的即是提取出等价条件表达式(递归实现)，建立<code>hashjoinplannode</code>。<br>注意需要根据<code>GetTupleIdx()</code>来分辨列属于哪个表，比如需要区分t1.v1 &#x3D; t2.v1和t2.v1 &#x3D; t1.v1.</p><h1 id="Task4-Sort-Limit-Executors-Window-Functions-Top-N-Optimization"><a href="#Task4-Sort-Limit-Executors-Window-Functions-Top-N-Optimization" class="headerlink" title="Task4: Sort + Limit Executors + Window Functions + Top-N Optimization"></a>Task4: Sort + Limit Executors + Window Functions + Top-N Optimization</h1><h2 id="Sort-Limit-Topn"><a href="#Sort-Limit-Topn" class="headerlink" title="Sort  Limit Topn"></a>Sort  Limit Topn</h2><p>sort算子需要自己写一个比较器(topn、windowfunc中也要用到)，同样是一个<strong>pipeline breakers</strong>，在init中完成sort，next中遍历。<br>limit算子注意对count的清0。<br>Top-n算子需要用到最小堆来实现动态跟随，这里可以使用这三个函数方便地调整堆结构：</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs cpp">std::<span class="hljs-built_in">push_heap</span>(min_heap_.<span class="hljs-built_in">begin</span>(), min_heap_.<span class="hljs-built_in">end</span>(), tuple_cmp);<br>std::<span class="hljs-built_in">pop_heap</span>(min_heap_.<span class="hljs-built_in">begin</span>(), min_heap_.<span class="hljs-built_in">end</span>(), tuple_cmp);<br>std::<span class="hljs-built_in">sort_heap</span>(min_heap_.<span class="hljs-built_in">begin</span>(), min_heap_.<span class="hljs-built_in">end</span>(), tuple_cmp);<br></code></pre></td></tr></table></figure><p>注意这里的push和pop并不真正影响了vector的大小，比如</p><ul><li>pop只是将元组放在了最后，需要手动<code>pop_back</code> vector将元组弹出。</li><li>push前需要手动将元组<code>emplace_back</code>进vector<br>关于topn优化器则只需简单地判断plannode的type即可。</li></ul><h2 id="Window-function"><a href="#Window-function" class="headerlink" title="Window function"></a>Window function</h2><p>(应该是最长的一个算子)<br>首先一定要读懂这个函数在干嘛：</p><ul><li>对于无orderby，计算聚合时是对整个分组进行操作，因此每个分组的每条输出都是一样的。像这样：<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><code class="hljs sql"><span class="hljs-keyword">create</span> <span class="hljs-keyword">table</span> t1(v1 <span class="hljs-type">int</span>);<br><span class="hljs-keyword">insert</span> <span class="hljs-keyword">into</span> t1 <span class="hljs-keyword">values</span> (<span class="hljs-number">-99999</span>), (<span class="hljs-number">99999</span>), (<span class="hljs-number">0</span>), (<span class="hljs-number">1</span>), (<span class="hljs-number">2</span>), (<span class="hljs-number">3</span>);<br><span class="hljs-keyword">select</span> <span class="hljs-built_in">count</span>(<span class="hljs-operator">*</span>) <span class="hljs-keyword">over</span> (), <span class="hljs-built_in">min</span>(v1) <span class="hljs-keyword">over</span> (), <span class="hljs-built_in">max</span>(v1) <span class="hljs-keyword">over</span> (), <span class="hljs-built_in">count</span>(v1) <span class="hljs-keyword">over</span> (), <span class="hljs-built_in">sum</span>(v1) <span class="hljs-keyword">over</span> () <span class="hljs-keyword">from</span> t1;<br><span class="hljs-comment">----</span><br><span class="hljs-number">6</span> <span class="hljs-number">-99999</span> <span class="hljs-number">99999</span> <span class="hljs-number">6</span> <span class="hljs-number">6</span><br><span class="hljs-number">6</span> <span class="hljs-number">-99999</span> <span class="hljs-number">99999</span> <span class="hljs-number">6</span> <span class="hljs-number">6</span><br><span class="hljs-number">6</span> <span class="hljs-number">-99999</span> <span class="hljs-number">99999</span> <span class="hljs-number">6</span> <span class="hljs-number">6</span><br><span class="hljs-number">6</span> <span class="hljs-number">-99999</span> <span class="hljs-number">99999</span> <span class="hljs-number">6</span> <span class="hljs-number">6</span><br><span class="hljs-number">6</span> <span class="hljs-number">-99999</span> <span class="hljs-number">99999</span> <span class="hljs-number">6</span> <span class="hljs-number">6</span><br><span class="hljs-number">6</span> <span class="hljs-number">-99999</span> <span class="hljs-number">99999</span> <span class="hljs-number">6</span> <span class="hljs-number">6</span><br></code></pre></td></tr></table></figure></li><li>对于有orderby，计算聚合时是从头到<strong>当前元组</strong>，同样对于表t1,有orderby的结果是这样的：<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><code class="hljs sql"><span class="hljs-keyword">select</span> <span class="hljs-built_in">count</span>(<span class="hljs-operator">*</span>) <span class="hljs-keyword">over</span> (<span class="hljs-keyword">order</span> <span class="hljs-keyword">by</span> v1), <span class="hljs-built_in">min</span>(v1) <span class="hljs-keyword">over</span> (<span class="hljs-keyword">order</span> <span class="hljs-keyword">by</span> v1), <span class="hljs-built_in">max</span>(v1) <span class="hljs-keyword">over</span> (<span class="hljs-keyword">order</span> <span class="hljs-keyword">by</span> v1), <span class="hljs-built_in">count</span>(v1) <span class="hljs-keyword">over</span> (<span class="hljs-keyword">order</span> <span class="hljs-keyword">by</span> v1), <span class="hljs-built_in">sum</span>(v1) <span class="hljs-keyword">over</span> (<span class="hljs-keyword">order</span> <span class="hljs-keyword">by</span> v1) <span class="hljs-keyword">from</span> t1;<br><span class="hljs-comment">----</span><br><span class="hljs-number">1</span> <span class="hljs-number">-99999</span> <span class="hljs-number">-99999</span> <span class="hljs-number">1</span> <span class="hljs-number">-99999</span><br><span class="hljs-number">2</span> <span class="hljs-number">-99999</span> <span class="hljs-number">0</span> <span class="hljs-number">2</span> <span class="hljs-number">-99999</span><br><span class="hljs-number">3</span> <span class="hljs-number">-99999</span> <span class="hljs-number">1</span> <span class="hljs-number">3</span> <span class="hljs-number">-99998</span><br><span class="hljs-number">4</span> <span class="hljs-number">-99999</span> <span class="hljs-number">2</span> <span class="hljs-number">4</span> <span class="hljs-number">-99996</span><br><span class="hljs-number">5</span> <span class="hljs-number">-99999</span> <span class="hljs-number">3</span> <span class="hljs-number">5</span> <span class="hljs-number">-99993</span><br><span class="hljs-number">6</span> <span class="hljs-number">-99999</span> <span class="hljs-number">99999</span> <span class="hljs-number">6</span> <span class="hljs-number">6</span><br></code></pre></td></tr></table></figure></li></ul><p>分组的意义就显而易见，根据by的列分组，比如partition by v1，v1值相同的就为一组。组间分离计算。<br>阅读hint，bustub规定了每个over的<code>order by</code>是相同的，而<code>partition by</code>则不一定相同，我们处理的顺序应该是：</p><ol><li>Sort the tuples as indicated in<code>ORDER BY</code>.</li><li>Generate the initial value for each partition</li><li>Combine values for each partition and record the value for each row.</li></ol><p>我们可以将情况分为两大类，有<code>order by</code>和无<code>order by</code>:</p><h3 id="无orderby："><a href="#无orderby：" class="headerlink" title="无orderby："></a>无orderby：</h3><p>对于每个window_func，遍历所有的tuples，分别计算partition_key and partition_value，并更新aht。在遍历完tuple后再得到结果。</p><h3 id="有orderby"><a href="#有orderby" class="headerlink" title="有orderby"></a>有orderby</h3><p>和上者的区别在于需要在遍历tuples的过程中就需要生成结果(因为是计算到当前元组)</p><p>注意一个点，ag有一个坑：在执行聚合函数时顺序并不是按照查询的顺序，比如:</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs sql"><span class="hljs-keyword">select</span> <span class="hljs-built_in">count</span>(<span class="hljs-operator">*</span>) <span class="hljs-keyword">over</span> (), <span class="hljs-built_in">min</span>(v1) <span class="hljs-keyword">over</span> (), <span class="hljs-built_in">max</span>(v1) <span class="hljs-keyword">over</span> (), <span class="hljs-built_in">count</span>(v1) <span class="hljs-keyword">over</span> (), <span class="hljs-built_in">sum</span>(v1) <span class="hljs-keyword">over</span> () <span class="hljs-keyword">from</span> t1;<br></code></pre></td></tr></table></figure><p>在遍历window_func时，第一个得到的函数可能是sum，第二个是count…那这里的不变量是什么呢？注意到在遍历window_func时，有<code>func_idx</code>，它是根据查询语句生成的，比如上述count* 的func_idx就是0，意思是它会输出结果的第一列。我们可以建立一个映射，对应func_idx和它对应的结果向量，like:</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs cpp">std::map&lt;<span class="hljs-type">u_int32_t</span>, std::vector&lt;Value&gt;&gt; map_values;<br></code></pre></td></tr></table></figure><p>最后附上通过截图<br><img src="/../images/32.png"></p><p>参考文章:<br><a href="https://zhuanlan.zhihu.com/p/674080359">CMU15445 Fall2023 Project 0-4 通关全记录</a><br><a href="https://zhuanlan.zhihu.com/p/679864362">CMU15-445 2023 Fall Project#3 - Query Execution</a><br><a href="https://zhuanlan.zhihu.com/p/587566135">做个数据库：2022 CMU15-445 Project3 Query Execution</a></p>]]></content>
    
    
    
  </entry>
  
  
  
  <entry>
    <title>CMU15-445 Proj2.Extendible hash index</title>
    <link href="/2023/12/13/Proj2.Extendible%20hash%20index/"/>
    <url>/2023/12/13/Proj2.Extendible%20hash%20index/</url>
    
    <content type="html"><![CDATA[<p>写了很久的一个proj，debug过程相当折磨<br><strong>注意</strong>：此proj需要在proj1的支撑下完成，务必确保proj1通过ag测试。</p><h1 id="Task1-Read-Write-Page-Guards"><a href="#Task1-Read-Write-Page-Guards" class="headerlink" title="Task1- Read&#x2F;Write Page Guards"></a>Task1- Read&#x2F;Write Page Guards</h1><p>实现 <code>BasicPageGuard</code>，它存储指向 <code>BufferPoolManager</code> 和 <code>Page</code> 对象的指针。page guard确保在相应的 Page 对象超出作用域时立即对其调用 <code>UnpinPage</code>。</p><p>需要对<code>BasicPageGuard</code>, <code>ReadPageGuard</code> 和<code>WritePageGuard</code>实现这四个函数：</p><ul><li><code>PageGuard(PageGuard &amp;&amp;that)</code>: Move constructor.</li><li><code>operator=(PageGuard &amp;&amp;that)</code>: Move operator.</li><li><code>Drop()</code>: Unpin and&#x2F;or unlatch.</li><li><code>~PageGuard()</code>: Destructor.</li></ul><h2 id="BasicPageGuard"><a href="#BasicPageGuard" class="headerlink" title="BasicPageGuard"></a>BasicPageGuard</h2><p>对于<code>BasicPageGuard</code>，注释写的很详细，要注意的是在<strong>移动赋值</strong>函数中，自己本身可能已经指向一个页面(如注释中所说：assumes that BasicPageGuard already has a page being guarded)，需要将自己清空且unpin(也就是调用Drop)。</p><p>Drop函数中要对page是否为空进行检查。</p><h2 id="ReadPageGuard-WritePageGuard"><a href="#ReadPageGuard-WritePageGuard" class="headerlink" title="ReadPageGuard WritePageGuard"></a>ReadPageGuard WritePageGuard</h2><ol><li>由于已经对guard_类(BasicPageGuard)实现了移动赋值函数，在构造和移值时可以对guard_直接使用<code>std::move()</code>,这里我们不用再去清除<code>that.guard_</code>的内容(在BasicPageGuard中的移动赋值函数中对that进行了清除)</li><li>在拿取that的guard_内容时，要注意对其锁的释放，在Drop时，也要注意释放锁。(这里同样要对页本身进行检查是否为空，避免重复释放锁)</li></ol><h2 id="UpgradeRead-UpgradeWrite"><a href="#UpgradeRead-UpgradeWrite" class="headerlink" title="UpgradeRead UpgradeWrite"></a>UpgradeRead UpgradeWrite</h2><p>纵观整个proj，我都没有用到过这两个函数，原因是我对注释中说的(The protected page is not evicted from the buffer pool during the upgrade)困惑，感觉很难实现，之后如果有时间或者要用到的时候再回来填个坑…</p><p>两个函数的使用的场景很明了，因为在bpm中，我们只有<code>NewPageGuarded</code>，而没有<code>NewReadPageGuarded</code>(or <code>NewWritePageGuarded</code>)，因此如果想要直接申请一个<code>ReadGuard </code>or <code>WriteGuard</code>，我们只能<code>NewPageGuarded</code>后Upgrade.</p><p>实现的思路跟BasicPageGuard的移动构造相似，不过这里是将自己的内容清空。</p><h2 id="NewGuard-FetchGuard"><a href="#NewGuard-FetchGuard" class="headerlink" title="NewGuard FetchGuard"></a>NewGuard FetchGuard</h2><p>在bpm中实现：</p><ul><li><code>FetchPageBasic(page_id_t page_id)</code></li><li><code>FetchPageRead(page_id_t page_id)</code></li><li><code>FetchPageWrite(page_id_t page_id)</code></li><li><code>NewPageGuarded(page_id_t *page_id)</code><br>实现很简单：调用bpm中的函数得到页，然后返回相应的Guard,在<code>FetchPageRead</code>和<code>FetchPageWrite</code>中要注意拿读写锁。</li></ul><h1 id="Task2-Extendible-Hash-Table-Pages"><a href="#Task2-Extendible-Hash-Table-Pages" class="headerlink" title="Task2 Extendible Hash Table Pages"></a>Task2 Extendible Hash Table Pages</h1><p><img src="/../images/20.png"></p><h2 id="Header-page"><a href="#Header-page" class="headerlink" title="Header_page"></a>Header_page</h2><p>跟以往的结构不同，23fall使用了三层结构(多了header)，header实现了对于目录页的映射，(应该是三层结构中最简单的一层):<br>要实现几个API(Set、Get、Size就不提及了)：</p><h3 id="Init"><a href="#Init" class="headerlink" title="Init"></a>Init</h3><p>赋值传入的max_depth,并将存储目录-&gt;page_id的映射初始化为<code>INVALID_PAGE_ID</code>即可。</p><h3 id="HashToDirectoryIndex"><a href="#HashToDirectoryIndex" class="headerlink" title="HashToDirectoryIndex"></a>HashToDirectoryIndex</h3><p>这里看测试：<br><strong>00</strong>000000000000001000000000000000 - 32768<br><strong>01</strong>000000000000001000000000000000 - 1073774592<br><strong>10</strong>000000000000001000000000000000 - 2147516416<br><strong>11</strong>000000000000001000000000000000 - 3221258240</p><p>不难发现是根据高max_depth位来作映射，因此我们取前max_depth位，方式为hash &gt;&gt; (32-max_depth)，<strong>这里注意max_depth为0的情况</strong>，右移32位会得到非法值，因此直接return 0即可。</p><h2 id="Directory-Page"><a href="#Directory-Page" class="headerlink" title="Directory_Page"></a>Directory_Page</h2><p>最复杂的一层，在extendible hashing中，不同的directory_idx可能指向同一个bucket,特别是在directory merge or directory split中，要将变化同步.</p><h3 id="结构认知"><a href="#结构认知" class="headerlink" title="结构认知"></a>结构认知</h3><p>来看一个例子:<br><img src="/../images/21.png"></p><figure class="highlight gherkin"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs gherkin">assume head_pageid = 0,directory pageid = 1,bucket_max_size = 3<br>======== DIRECTORY (global_depth_: 1) ========<br>|<span class="hljs-string"> bucket_idx </span>|<span class="hljs-string"> page_id </span>|<span class="hljs-string"> local_depth </span>|<br>|<span class="hljs-string"> 0 </span>|<span class="hljs-string"> 2 </span>|<span class="hljs-string"> 1 </span>|<br>|<span class="hljs-string"> 1 </span>|<span class="hljs-string"> 3 </span>|<span class="hljs-string"> 1 </span>|<br>================ END DIRECTORY ================<br></code></pre></td></tr></table></figure><p>当我们要插入22，bucket满了，需要增加bucket的本地深度和目录页的全局深度，并rehash这四个值，重新分配到正确的桶中，此时这四个数根据2位来分配：</p><ul><li>16:100<strong>00</strong>   4: 001<strong>00</strong></li><li>6: 001<strong>10</strong>   22:101<strong>10</strong><br>因此16和4去到第一个桶(idx&#x3D;00)，6和22去到第三个桶(idx&#x3D;10)<br>仅仅到这，我们的目录应该是这样的:<figure class="highlight gherkin"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><code class="hljs gherkin">======== DIRECTORY (global_depth_: 2) ========<br>|<span class="hljs-string"> bucket_idx </span>|<span class="hljs-string"> page_id </span>|<span class="hljs-string"> local_depth </span>|<br>|<span class="hljs-string"> 0 </span>|<span class="hljs-string"> 2 </span>|<span class="hljs-string"> 2 </span>|<br>|<span class="hljs-string"> 1 </span>|<span class="hljs-string"> 3 </span>|<span class="hljs-string"> 1 </span>|<br>|<span class="hljs-string"> 2 </span>|<span class="hljs-string"> 4 </span>|<span class="hljs-string"> 2 </span>|<br>|<span class="hljs-string"> 3 </span>|<span class="hljs-string"> ? </span>|<span class="hljs-string"> ? </span>|<br>================ END DIRECTORY ================<br></code></pre></td></tr></table></figure>看最终结果，我们缺少了把第四个桶(idx&#x3D;11)指向pageid为3的页的映射过程。<br><img src="/../images/22.png"><br>我们想要的结果是：<figure class="highlight gherkin"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><code class="hljs gherkin">======== DIRECTORY (global_depth_: 2) ========<br>|<span class="hljs-string"> bucket_idx </span>|<span class="hljs-string"> page_id </span>|<span class="hljs-string"> local_depth </span>|<br>|<span class="hljs-string"> 0 </span>|<span class="hljs-string"> 2 </span>|<span class="hljs-string"> 2 </span>|<br>|<span class="hljs-string"> 1 </span>|<span class="hljs-string"> 3 </span>|<span class="hljs-string"> 1 </span>|<br>|<span class="hljs-string"> 2 </span>|<span class="hljs-string"> 4 </span>|<span class="hljs-string"> 2 </span>|<br>|<span class="hljs-string"> 3 </span>|<span class="hljs-string"> 3 </span>|<span class="hljs-string"> 1 </span>|<br>================ END DIRECTORY ================<br></code></pre></td></tr></table></figure>因此，这里<code>IncrGlobalDepth</code>要做的另一件事(一件是global_depth++)是将新的不被设置指向page的bucket_idx，指向他们应该指向的，而这里应该指向的就是<strong>SplitImageIndex</strong>，其实上面分割满桶的过程中，就已经用到了分割映像(00-10)。<br>那么11的SplitImageIndex应该是谁？想象我们再插入一系列奇数:1、3、5、7，此时第二个桶满了，我们需要把1357再分成两组:</li><li>1: 00<strong>01</strong> 5: 01<strong>01</strong></li><li>3: 00<strong>11</strong> 7: 01<strong>11</strong><br>显然，01和11是一组，到这，相信读者已经有一种感觉了，这不就是将第二位与1异或嘛？:</li><li>00 ^ 10 &#x3D; 10</li><li>01 ^ 10 &#x3D; 11<br>这里第二个数是通过(1 &lt;&lt; depth)生成的，而depth是取global_depth还是local_depth？又或者在后面directory shrink的过程中，会不会不一样？交给读者自己思考。</li></ul><p>几个api实现：</p><h3 id="Init-1"><a href="#Init-1" class="headerlink" title="Init"></a>Init</h3><p>赋值max_depth，对全局深度和局部深度初始化为0，将bucket-&gt;page_id的映射初始化为INVALID.</p><h3 id="HashToBucketIndex"><a href="#HashToBucketIndex" class="headerlink" title="HashToBucketIndex"></a>HashToBucketIndex</h3><p>观察上述例子，易知bucket_idx为 hash % size</p><h3 id="CanShrink"><a href="#CanShrink" class="headerlink" title="CanShrink"></a>CanShrink</h3><p>根据文档所说，只有当每个bucket的本地深度都小于全局深度时，才可以进行目录Shrink。</p><h3 id="SetLocalDepth"><a href="#SetLocalDepth" class="headerlink" title="SetLocalDepth"></a>SetLocalDepth</h3><p>要同时对splitimageindex作同步，如上述例子中，若要改变第二个桶的本地深度，第四个桶的本地深度应该也变化。(因为俩者指向的是同一页)</p><h2 id="Bucket-Page"><a href="#Bucket-Page" class="headerlink" title="Bucket_Page"></a>Bucket_Page</h2><p>这一层是实际存储键值对的。几个函数实现都很简单，无非是对array_存储的键值对的操作，不过多赘述。</p><h3 id="Init-2"><a href="#Init-2" class="headerlink" title="Init"></a>Init</h3><p>赋值max_size，初始化size，将array_存的键值对初始化为<code>&#123;&#123;-1&#125;, &#123;&#125;&#125;</code>。</p><h1 id="Task3-Extendible-Hashing-Implementation"><a href="#Task3-Extendible-Hashing-Implementation" class="headerlink" title="Task3 Extendible Hashing Implementation"></a>Task3 Extendible Hashing Implementation</h1><p>使用task2中写的三层索引来实现对记录的插入、删除和点搜索。我们要做的就是给一个键值对，一层层找到他该去的bucket(如果有)。<br>先谈谈有关实现细节：</p><h3 id="Init-3"><a href="#Init-3" class="headerlink" title="Init"></a>Init</h3><p>参考文档所说，<code>When you first create an empty hash table, it should only have the (one and only) header page. Directory pages and bucket pages should be created on demand.</code>这里我们只需要新建head页并且init就行。对于目录页和桶页，在<strong>插入</strong>的时候<strong>按需生成</strong></p><h3 id="Indexing"><a href="#Indexing" class="headerlink" title="Indexing"></a>Indexing</h3><p>在操作过程中，我们会碰到两种索引，header-&gt;directory ，directory-&gt;bucket，基本的流程都一样，先获取headerPageid，as(or asmut)获得header，再<code>HashToDirectoryIndex</code>，得到directory_idx，根据idx得到page id，as(or asmut)获得directory ，对于bucket则是相同的步骤。</p><h3 id="Bucket-Splitting"><a href="#Bucket-Splitting" class="headerlink" title="Bucket Splitting"></a>Bucket Splitting</h3><p>在上面task2中讲directory_page时已经提到，读者若不清楚可以往回再看看。注意这里简单的做法是<strong>插入时</strong>发现桶满了再Split,而不是当<strong>插入后</strong>桶满了就Split，有细微的差别。</p><h3 id="Bucket-Merging"><a href="#Bucket-Merging" class="headerlink" title="Bucket Merging"></a>Bucket Merging</h3><p>与Splitting针对于Insert不同，Merging是针对于Remove的，根据文档所说:</p><blockquote><p>To keep things relatively simple, we provide the following rules for merging:</p><blockquote><ol><li>Only empty buckets can be merged. 只有空桶可以被合并。</li><li>Buckets can only be merged with their split image if their split image has the same local depth.只有桶和它的分割映像桶有相同的本地深度时才可以合并</li><li>You should keep merging recursively if the <strong>new split image</strong> of the merged bucket is empty.若合并后的桶的分割映像桶也是空的，则继续合并</li></ol></blockquote></blockquote><p>这里注意，不是当前桶和它的分割映像桶必须都是空的才能合并，实际场景应该是：</p><ol><li>remove一个键值对后，当前桶空了，则进行merge，而如果当前桶非空，split image是空的，是不进行合并的。</li><li>but 在合并一次后，如果该合并桶的split image是空的，则不管当前桶是否空，继续合并。<br>处理起来也很简单，remove后，检查当前桶是否空，若空则调用merge，而merge中的条件是当前桶和split image任一为空。</li></ol><p>在merge中需要将本地深度减一，这就相当于split的时候要将本地深度加一，merge的意义就是不需要这多一位的深度即可完成索引。</p><h3 id="Directory-Grow-or-Shrink"><a href="#Directory-Grow-or-Shrink" class="headerlink" title="Directory Grow or Shrink"></a>Directory Grow or Shrink</h3><ul><li>Grow: 当bucket满时，需要增加本地深度，当本地深度大于全局深度时，就需要directory grow。</li><li>Shirnk: 在merge后，检查Directory.Canshrink。true则缩减全局深度，注意把shrink掉的bucket的pageid设为Invalid</li></ul><h3 id="Bugs"><a href="#Bugs" class="headerlink" title="Bugs"></a>Bugs</h3><ol><li><code>page -1 not in range </code>是访问到了空的directory or bucket，问题大概是没有按需生成或者没有及时return。比如insert时一路走下去，没有directory或者没有bucket时就要生成，(生成后记得更新映射）而remove或者getvalue找不到时，就直接return false.</li><li>注意：<code>For this semester, the hash table is intend to support only **unique keys**. This means that the hash table should return false if the user tries to insert duplicate keys.</code>当插入已有值时，直接return false.</li><li>在ag上的一些测试中，bpm的size只有3，而headpage,directorypage已经占了两个，我们只有一个页可以用来存储bucket。显然，我们这里需要及时<code>drop</code>掉不用的(用不到的)headpage或者是directorypage以供bucketpage存储.</li><li>如果效率不足，尝试优化之前的bpm。<br>由于时间线有点长，暂时就想到这么多，想到再更新。</li></ol><p>做到这，就可以扔ag验证task1、2、3的正确性了。待能通过非并行测试后，再进行task4.(通不过的话就是<strong>开心</strong>的debug时间啦)</p><h1 id="Task4-Concurrency-Control"><a href="#Task4-Concurrency-Control" class="headerlink" title="Task4 Concurrency Control"></a>Task4 Concurrency Control</h1><p>使用task1实现的 <code>FetchPageWrite</code> <code>FetchPageRead</code>替换之前的BasicPageGuard(如果用了的话)<br>策略大概是：</p><ul><li>GetValue 全部使用readguard.</li><li>Insert 和Remove 全部使用writeguard.</li><li>因为readguard和writeguard有锁，记得及时drop不要的页.</li></ul><p>由于是code后复盘写的文章，可能所处的高度会有些高，适合对proj有一定基础和认知来阅读，欢迎指正和学习。</p><p>最后附上通过截图：<br><img src="/../images/23.png"></p><p>参考文章:<br><a href="https://www.geeksforgeeks.org/extendible-hashing-dynamic-approach-to-dbms/">哈希表</a><br><a href="https://zihao256.github.io/p/517dd8ea.html">Project2: Extendible Hash Index</a></p>]]></content>
    
    
    
  </entry>
  
  
  
  <entry>
    <title>CMU15-445 Proj1.BUFFER POOL</title>
    <link href="/2023/11/26/Proj1.Buffer%20pool/"/>
    <url>/2023/11/26/Proj1.Buffer%20pool/</url>
    
    <content type="html"><![CDATA[<p>先放通过截图(23fa)：<br><img src="/../images/1.png"><br>记录笔者作业CMU15-445(23fa)的proj1中的实现和踩过的坑，第一个坑:由于笔者在proj0的时候一直跟着2023sp的在写，在写pro1中发现代码中要我使用disk_scheduler来调度磁盘的读写，而2023sp里面的文档并未提及这一点，后来发现由于其bustub早已更新了2023fa的库，而我当时clone的也就是这个库(傻傻地对着23sp的文档写23fa的proj…)。于是就跑去跟2023fa了，好在Andy老师对于2023fa也开放了lec和ag，(跪了)，不过ag现在(2023.11.26)只开放到proj2，期待后面的更新。</p><h2 id="Task1-LRU-K-Replacement-Policy"><a href="#Task1-LRU-K-Replacement-Policy" class="headerlink" title="Task1 - LRU-K Replacement Policy"></a>Task1 - LRU-K Replacement Policy</h2><p>当缓冲区满时，我们需要考虑移出某一帧，为新帧留出位置，这里用到的方法是的<code>LRU-K</code>，是LRU(Least Recently Used)的衍生，在LRU-K中，评判规则是<code>backward k-distance</code>，代表该帧在当前时间戳和前k次时间戳的差，显然这个时间差越长，代表此帧的使用频率越小，我们驱逐的就是<code>k-distance</code><strong>最大</strong>的帧，这就是这个task要实现的：<br>在<code>lru_k_replacer.h</code>实现<code>LRUKReplacer</code>类，在<code>lru_k_replacer.cpp</code>实现相应方法:(注意加锁确保线程安全)</p><h3 id="Evict-frame-id-t-frame-id"><a href="#Evict-frame-id-t-frame-id" class="headerlink" title="Evict(frame_id_t* frame_id):"></a>Evict(frame_id_t* frame_id):</h3><p>驱逐与 <code>Replacer</code> 正在跟踪的所有其他可驱逐帧相比具有最大后向 k 距离的帧(若不足K次访问，则记k-distance为+inf。在输出参数中存储帧 ID 并返回 True。如果没有可驱逐的帧，则返回 False。<br>这里分为三种情况：</p><ol><li>无<code>k-distance</code>为inf的帧：则对所有可驱逐的帧进行<strong>LRU-K</strong>算法驱逐</li><li>有一帧的<code>k-distance</code>为inf:对其驱逐</li><li>多帧的k-distance为inf，<strong>这里需要注意</strong> 官方文档及注释都写的有些晦涩，简单来说就是驱逐这些帧中最早出现的。如考虑这个replacer_: k &#x3D; 3, 记录序列从旧到新为:<figure class="highlight basic"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs basic"><span class="hljs-symbol">1 </span><span class="hljs-number">2</span> <span class="hljs-number">3</span> <span class="hljs-number">4</span> <span class="hljs-number">1</span> <span class="hljs-number">2</span> <span class="hljs-number">3</span> <span class="hljs-number">1</span> <span class="hljs-number">2</span> <br></code></pre></td></tr></table></figure>这里1和2都有<strong>3次</strong>的访问记录，而3和4少于3次，因此属于上述的第三种情况，这里按照LRU的策略，我们应该驱逐最近最旧的访问，也就是4。但是在LRU-K的访问中，我们就简单地驱逐最早出现的帧，这里也就是3.</li></ol><h3 id="RecordAccess-frame-id-t-frame-id"><a href="#RecordAccess-frame-id-t-frame-id" class="headerlink" title="RecordAccess(frame_id_t frame_id) :"></a>RecordAccess(frame_id_t frame_id) :</h3><p>记录给定帧 ID 在当前时间戳被访问的情况。在代码中表现为更新指定<code>LRUKNode</code>的history。记得自己手动增加当前时间戳。</p><h3 id="Remove-frame-id-t-frame-id"><a href="#Remove-frame-id-t-frame-id" class="headerlink" title="Remove(frame_id_t frame_id):"></a>Remove(frame_id_t frame_id):</h3><p>清除与一个帧相关的所有访问历史记录。将帧从帧map中删除，同时减小<code>LRUKReplacer</code> 的大小。</p><h3 id="SetEvictable-frame-id-t-frame-id-bool-set-evictable"><a href="#SetEvictable-frame-id-t-frame-id-bool-set-evictable" class="headerlink" title="SetEvictable(frame_id_t frame_id, bool set_evictable) :"></a>SetEvictable(frame_id_t frame_id, bool set_evictable) :</h3><p>该方法控制帧是否可驱逐。并且控制 <code>LRUKReplacer</code> 的大小。(注意不能仅根据要设置的布尔值来判断，还要看该帧本来的情况。)</p><h3 id="Size"><a href="#Size" class="headerlink" title="Size () :"></a>Size () :</h3><p>返回当前在 <code>LRUKReplace</code> 中的可驱逐帧的数量。</p><h2 id="Task2-Disk-Scheduler"><a href="#Task2-Disk-Scheduler" class="headerlink" title="Task2 Disk Scheduler"></a>Task2 Disk Scheduler</h2><p>该组件负责调度 DiskManager 上的读写操作。在 <code>disk_scheduler.h</code> 中实现一个名为 DiskScheduler 的新类，并在 <code>disk_scheduler.cpp</code> 中实现相应的实现文件。<br>要实现的两个方法：</p><h3 id="Schedule-DiskRequest-r"><a href="#Schedule-DiskRequest-r" class="headerlink" title="Schedule(DiskRequest r):"></a>Schedule(DiskRequest r):</h3><p>调度请求。即将请求r加入到队列中排队以等待DiskManager执行读写。</p><h3 id="StartWorkerThread"><a href="#StartWorkerThread" class="headerlink" title="StartWorkerThread():"></a>StartWorkerThread():</h3><p>后台工作线程的启动方法，用于处理计划请求。工作线程在 DiskScheduler 构造函数中创建，并调用此方法。该方法负责获取队列中的请求并将其分派给 DiskManager进行page read or page write。在调用 DiskScheduler 的析构函数之前，该方法不应返回。<br>其中队列可以直接用提供的<code>Channel</code>类，其包括Put和Get两个方法，Get自带了等待的环节，在获取请求时方便了很多。<br>这个Task的关键是读懂文档和注释，我们看启动代码，在DiskScheduler的析构函数中有:</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs cpp"><span class="hljs-comment">// Put a `std::nullopt` in the queue to signal to exit the loop</span><br>request_queue_.<span class="hljs-built_in">Put</span>(std::<span class="hljs-literal">nullopt</span>);<br></code></pre></td></tr></table></figure><p>自然地，在StartWorkerThread中我们就是一个while(true)，直到Get到的队列是析构函数发出的信号：nullopt。退出循环，对于其他正常的请求，我们分配给DiskManager进行对磁盘的读写操作，<strong>注意，这里读写完一定要对call_back设置true值以实现异步处理</strong>。<br>一个语法的点：传DiskRequest时，记得加上std::move</p><h2 id="Task3-Buffer-Pool-Manager"><a href="#Task3-Buffer-Pool-Manager" class="headerlink" title="Task3 Buffer Pool Manager"></a>Task3 Buffer Pool Manager</h2><p>系统中的所有内存中页都由 Page 对象表示。Page 对象只是缓冲池中的内存容器，因此不是特定于唯一页面的。也就是说，每个 Page 对象都包含一块内存，<strong>相同</strong>的 Page 对象可能在整个系统生命周期中包含<strong>不同</strong>的物理页，<code>Page</code>只是内存的抽象。Page 对象的标识符(Page _ id)跟踪它包含的物理页面; 如果 Page 对象不包含物理页面，那么它的 Page _ id 必须设置为 <code>INVALID _ PAGE _ ID</code>。<br>每个 Page 对象还维护一个计数器，用于计算<code>pinned</code>该页面的线程数。不能释放被<code>pinned</code>的 Page。每个 Page 对象还跟踪它是否是<code>dirty</code>。 必须将<code>dirty Page</code>写回磁盘，然后才能重用该对象。<br>BufferPoolManager 实现将使用Task1中创建的 LRUKReplace 类跟踪 Page 对象何时被访问(将 page _ id 映射到 frame _ id)，以便在必须释放一个<code>frame</code>以腾出空间从磁盘复制一个新的物理页面时决定<code>evict</code>哪个对象。同时使用Task2中创建的调度器来实现对<code>dirty page</code>的写入，和<code>fetchpage</code>时对page的读取。<strong>因此，建议确保前两个类实现没问题的情况下再进行Task的作业，能免去很多无效的内耗检查(</strong>.<br>在<code>buffer pool manager.cpp</code>中实现：</p><h3 id="NewPage-page-id-t-page-id"><a href="#NewPage-page-id-t-page-id" class="headerlink" title="NewPage(page_id_t* page_id) :"></a>NewPage(page_id_t* page_id) :</h3><p>新建页，几个步骤：</p><ol><li>通过<code>AllocatePage()</code> 获得新的page_id</li><li>再取frame帧跟踪page，先从freelist里取，若没有再到replacer_里去evict(至此，Page结构的两个重要数据<code>page_id 和 frame_id</code>都已得到)</li><li>初始化Page，赋值相关的属性，并将其加入到<code>Page_table</code>中。</li><li><code>pin</code>Page : <ol><li>添加访问记录</li><li>设置不可驱逐</li><li>pin_cout ++</li></ol></li></ol><h3 id="FetchPage-page-id-t-page-id"><a href="#FetchPage-page-id-t-page-id" class="headerlink" title="FetchPage(page_id_t page_id)"></a>FetchPage(page_id_t page_id)</h3><p>取页，分两种情况：</p><ol><li>page已在池里，则直接pin该page</li><li>page不在池中：先取跟踪该page的帧(若freelist和replacer_中都已空，无法跟踪该帧，返回nullptr)，后生成新的page页，并使用调度器读取该page_id物理页上的内容。注意由于并发的存在，这里读磁盘时，一定要等待读取完成，(<code>future.get()</code>)。对page完善后，同样地，pin page.</li></ol><h3 id="UnpinPage-page-id-t-page-id-bool-is-dirty"><a href="#UnpinPage-page-id-t-page-id-bool-is-dirty" class="headerlink" title="UnpinPage(page_id_t page_id, bool is_dirty)"></a>UnpinPage(page_id_t page_id, bool is_dirty)</h3><p>取消对某页的引用，代码上表现为：找到page，将其<code>pin count</code>减1，若减完后<code>pin count</code>为0，则设置该page可驱逐。设置is_dirty标志指示前后是否改变(<strong>注意一个页会有许多引用，一个引用没修改该页不代表另外的页没修改，只要一个引用修改了该页，那么该页就是dirty page。因此这里不是简单地赋值，而是要用或运算</strong>)</p><h3 id="FlushPage-page-id-t-page-id"><a href="#FlushPage-page-id-t-page-id" class="headerlink" title="FlushPage(page_id_t page_id)"></a>FlushPage(page_id_t page_id)</h3><p>无论该页状态如何，将其内容写入磁盘。同时设置<code>is_dirty</code> 为 false。同样地，像上述FetchPage提到，在磁盘操作的时候，一定要等待操作完成。</p><h3 id="FlushAllPages"><a href="#FlushAllPages" class="headerlink" title="FlushAllPages()"></a>FlushAllPages()</h3><p>对记录的page调用FlushPage</p><h3 id="DeletePage-page-id-t-page-id"><a href="#DeletePage-page-id-t-page-id" class="headerlink" title="DeletePage(page_id_t page_id)"></a>DeletePage(page_id_t page_id)</h3><p>删除页，若找不到该页，直接返回true。若该页被pin，无法删除，返回false。将page从page_table删除，同时取消对其的跟踪，将帧移出replacer并加入到freelist中，reset该页的元数据，最后调用DeallocatePage(它模拟在磁盘上释放页面)。</p><h2 id="AG测试"><a href="#AG测试" class="headerlink" title="AG测试"></a>AG测试</h2><p>当你通过了本地测试，<code>make submit-p1</code>满怀自信地去上传ag时，一片红让你怀疑人生(本地测试用例实在太少了，建议读者自己多写几个测试实现，而不是像我一样把ag当debug机器)</p><p>提两个踩的坑:</p><ol><li>遇到超时，大概率是死锁问题</li><li>关于内存泄漏，对于replacer_中创造的LRUKNode节点，记得在析构函数destroy replacer的时候删除</li><li>关于<em>BufferPoolManagerTest.HardTest_4</em>，把BufferPoolManager函数中的锁换成: <figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs cpp"><span class="hljs-function">std::scoped_lock&lt;std::mutex&gt; <span class="hljs-title">locker</span><span class="hljs-params">(latch_)</span></span>;<br></code></pre></td></tr></table></figure>即可解决。</li></ol><p>祝大家都能满分通过 :）</p>]]></content>
    
    
    
  </entry>
  
  
  
  <entry>
    <title>CMU15-445 Proj0.C++ Primer</title>
    <link href="/2023/11/18/Proj0.C++%20Primer/"/>
    <url>/2023/11/18/Proj0.C++%20Primer/</url>
    
    <content type="html"><![CDATA[<p>先放通过截图(23sp)：<br><img src="/../images/0.jpg"><br>15-445的入课cpp测试(CMU的学生通不过的话会被退课😨)，由于本人没有cpp基础，在各种语法上还是挣扎了很久，包括模版、智能指针等，若读者要刷这门课，还是要先学一下这些知识，否则就是痛苦地跟编译作斗争:(<br><a href="https://15445.courses.cs.cmu.edu/spring2023/project0/">Proj链接</a></p><h2 id="Task1-Copy-On-Write-Trie"><a href="#Task1-Copy-On-Write-Trie" class="headerlink" title="Task1 Copy-On-Write Trie"></a>Task1 Copy-On-Write Trie</h2><p>修改<code>trie.h</code>和<code>trie.cpp</code>文件来实现一个COW的Trie，关键点就是我们不在原本的Trie上操作，而是重用不变的旧节点，创建修改后的新的节点，而后返回新的根。</p><p>task1中要实现三个方法：</p><h3 id="Get-key"><a href="#Get-key" class="headerlink" title="Get(key)"></a>Get(key)</h3><p>意义明确，返回与键对应的值，思路也很显然：遍历整个Trie，找到key对应的TrieNode。主要还是一些语法上的问题、编译上的错误。有个注意点是，启动代码注释中提到的强制类型转换:</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs cpp"><span class="hljs-comment">// After you find the node, you should use `dynamic_cast` to cast it to `const TrieNodeWithValue&lt;T&gt; *`.</span><br></code></pre></td></tr></table></figure><h3 id="Put-key"><a href="#Put-key" class="headerlink" title="Put(key)"></a>Put(key)</h3><p>在键上写入值或覆盖值。难于Get方法的点在于，需要对<strong>节点</strong>进行操作。自然地，我们一定会创建一个带着新值的该键的节点，然后将该节点加入到其父节点的children map中，这是一个<strong>自底向上</strong>的过程，因此在遍历到键的过程中，我们想到将之前相同的节点存入一个栈中。而后完成一层层的操作。<br>因此该过程大致为：</p><ol><li>遍历到键，且把相同的节点压入到栈中。</li><li>创建要put的节点</li><li>自底向上复制节点</li><li>返回新的Trie</li></ol><p>有个注意点同样在注释中:</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs cpp"><span class="hljs-comment">// Note that `T` might be a non-copyable type. Always use `std::move` when creating `shared_ptr` on that value.</span><br></code></pre></td></tr></table></figure><h3 id="Remove-key"><a href="#Remove-key" class="headerlink" title="Remove(key)"></a>Remove(key)</h3><p>删除键的值，由于要操作节点，因此总体流程与<code>Put</code>方法类似，需要注意的点是我们需要<strong>删除</strong>那些<br>没有<code>children_</code>并且不为<strong>值节点</strong>的节点，(RemoveFreeTest测试考察了这一点)</p><p>至此Task1结束，主要是熟悉trie.h的各种定义。</p><p>测试实现：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs shell">cd build<br>make trie_test trie_store_test -j$(nproc)<br>make trie_noncopy_test trie_store_noncopy_test -j$(nproc)<br>./test/trie_test<br>./test/trie_noncopy_test<br></code></pre></td></tr></table></figure><h2 id="Task2-并发存储"><a href="#Task2-并发存储" class="headerlink" title="Task2 并发存储"></a>Task2 并发存储</h2><p>修改<code>trie_store.cpp</code>实现对Trie的并发操作，学过OS的应该都不陌生，当对Trie并发地进行操作时，就需要加上锁了，此Task就是实现这个。没什么可讲的，可以直接调用Task1实现的函数，操作时加上对应的锁就行。</p><p>测试实现:</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs shell">cd build<br>make trie_test trie_store_test -j$(nproc)<br>make trie_noncopy_test trie_store_noncopy_test -j$(nproc)<br>./test/trie_store_test<br>./test/trie_store_noncopy_test<br></code></pre></td></tr></table></figure><h2 id="Task3-调试"><a href="#Task3-调试" class="headerlink" title="Task3 调试"></a>Task3 调试</h2><p>需要在<code>trie_answer.h</code>中填入有关<code>trie_debug_test.cpp</code>中trie结构的信息，随机数生成不一样，可以将trie结构初始化改成：</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><code class="hljs cpp"><span class="hljs-keyword">auto</span> trie = <span class="hljs-built_in">Trie</span>();<br>trie = trie.<span class="hljs-built_in">Put</span>&lt;<span class="hljs-type">uint32_t</span>&gt;(<span class="hljs-string">&quot;65&quot;</span>, <span class="hljs-number">25</span>);<br>trie = trie.<span class="hljs-built_in">Put</span>&lt;<span class="hljs-type">uint32_t</span>&gt;(<span class="hljs-string">&quot;61&quot;</span>, <span class="hljs-number">65</span>);<br>trie = trie.<span class="hljs-built_in">Put</span>&lt;<span class="hljs-type">uint32_t</span>&gt;(<span class="hljs-string">&quot;82&quot;</span>, <span class="hljs-number">84</span>);<br>trie = trie.<span class="hljs-built_in">Put</span>&lt;<span class="hljs-type">uint32_t</span>&gt;(<span class="hljs-string">&quot;2&quot;</span>, <span class="hljs-number">42</span>);<br>trie = trie.<span class="hljs-built_in">Put</span>&lt;<span class="hljs-type">uint32_t</span>&gt;(<span class="hljs-string">&quot;16&quot;</span>, <span class="hljs-number">67</span>);<br>trie = trie.<span class="hljs-built_in">Put</span>&lt;<span class="hljs-type">uint32_t</span>&gt;(<span class="hljs-string">&quot;94&quot;</span>, <span class="hljs-number">53</span>);<br>trie = trie.<span class="hljs-built_in">Put</span>&lt;<span class="hljs-type">uint32_t</span>&gt;(<span class="hljs-string">&quot;20&quot;</span>, <span class="hljs-number">35</span>);<br>trie = trie.<span class="hljs-built_in">Put</span>&lt;<span class="hljs-type">uint32_t</span>&gt;(<span class="hljs-string">&quot;3&quot;</span>, <span class="hljs-number">57</span>);<br>trie = trie.<span class="hljs-built_in">Put</span>&lt;<span class="hljs-type">uint32_t</span>&gt;(<span class="hljs-string">&quot;93&quot;</span>, <span class="hljs-number">30</span>);<br>trie = trie.<span class="hljs-built_in">Put</span>&lt;<span class="hljs-type">uint32_t</span>&gt;(<span class="hljs-string">&quot;75&quot;</span>, <span class="hljs-number">29</span>);<br></code></pre></td></tr></table></figure><p>然后根据要求，输出看结果，填入答案即可。(感觉是很无趣的一环)</p><h2 id="Task4-SQL-String-Functions"><a href="#Task4-SQL-String-Functions" class="headerlink" title="Task4 SQL String Functions"></a>Task4 SQL String Functions</h2><p>在<code>string_expression.h</code>中加入大小写转换的功能。在<code>plan_func_call.cpp</code>中实现对刚才写的功能的调用(跟着注释来写就好)</p><p>测试实现:</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs shell">cd build<br>make -j`nproc` shell<br>./bin/bustub-shell<br><span class="hljs-meta prompt_">bustub&gt; </span><span class="language-bash"><span class="hljs-keyword">select</span> upper(<span class="hljs-string">&#x27;AbCd&#x27;</span>), lower(<span class="hljs-string">&#x27;AbCd&#x27;</span>);</span><br></code></pre></td></tr></table></figure><p>结果出现<code>ABCD abcd</code>即正确。</p><h2 id="提交代码"><a href="#提交代码" class="headerlink" title="提交代码"></a>提交代码</h2><h3 id="Format"><a href="#Format" class="headerlink" title="Format"></a>Format</h3><p>公开课的特色之一：Style Check，<br>官方给出的三行命令检查：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs shell"><span class="hljs-meta prompt_">$ </span><span class="language-bash">make format</span><br><span class="hljs-meta prompt_">$ </span><span class="language-bash">make check-lint</span><br><span class="hljs-meta prompt_">$ </span><span class="language-bash">make check-clang-tidy-p0</span><br></code></pre></td></tr></table></figure><p>在此ag中，不满足上述三种规则的代码会直接评0分。<br>由于本人在terminal下只能执行第二条命令，第一条和第三条都报错，转而使用了vscode的自动格式化：<br>在Macos的环境下大致配置如下：</p><ol><li>在vscode拓展中安装<code>Clang-Format</code></li><li>阅读readme,在.vscode文件夹下的<code>settings.json</code>中配置如下两行:<figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs json"><span class="hljs-attr">&quot;editor.formatOnSave&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-literal"><span class="hljs-keyword">true</span></span><span class="hljs-punctuation">,</span> <span class="hljs-comment">// 保存时自动格式化</span><br><span class="hljs-attr">&quot;clang-format.executable&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-string">&quot;/absolute/path/to/clang-format&quot;</span> <span class="hljs-comment">// 路径(等下要改)</span><br></code></pre></td></tr></table></figure></li><li>若安装过brew,在terminal中安装format:<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs shell">brew install clang-format<br></code></pre></td></tr></table></figure></li><li>获取format路径，在terminal中输入<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs shell">which clang-format<br></code></pre></td></tr></table></figure></li><li>将输出结果复制覆盖上述json文件的路径。</li><li>在vscode中打开要格式化的代码文件，cmd+s保存即可自动格式化。<br>此时应该满足官方的前两条规则，第三条是有关代码本身，包括变量命名的规范，循环条件的冗余等等。(若安装了<code>clangd</code>拓展，在ide中会如编译错误一样标红显示，注意进行修改)</li></ol><p>当一切完成，打包文件，在命令行中输入:</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs shell">cd build<br>make submit-p0<br></code></pre></td></tr></table></figure><p>会在根目录下自动生成<em>proj0-submission.zip</em>压缩包，上传ag(无法直接导入github库)，虔诚地等待打分……</p>]]></content>
    
    
    
  </entry>
  
  
  
  <entry>
    <title>Hello World</title>
    <link href="/2023/11/08/hello-world/"/>
    <url>/2023/11/08/hello-world/</url>
    
    <content type="html"><![CDATA[<p>Welcome to <a href="https://hexo.io/">Hexo</a>! This is your very first post. Check <a href="https://hexo.io/docs/">documentation</a> for more info. If you get any problems when using Hexo, you can find the answer in <a href="https://hexo.io/docs/troubleshooting.html">troubleshooting</a> or you can ask me on <a href="https://github.com/hexojs/hexo/issues">GitHub</a>.</p><h2 id="Quick-Start"><a href="#Quick-Start" class="headerlink" title="Quick Start"></a>Quick Start</h2><h3 id="Create-a-new-post"><a href="#Create-a-new-post" class="headerlink" title="Create a new post"></a>Create a new post</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">$ hexo new <span class="hljs-string">&quot;My New Post&quot;</span><br></code></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/writing.html">Writing</a></p><h3 id="Run-server"><a href="#Run-server" class="headerlink" title="Run server"></a>Run server</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">$ hexo server<br></code></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/server.html">Server</a></p><h3 id="Generate-static-files"><a href="#Generate-static-files" class="headerlink" title="Generate static files"></a>Generate static files</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">$ hexo generate<br></code></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/generating.html">Generating</a></p><h3 id="Deploy-to-remote-sites"><a href="#Deploy-to-remote-sites" class="headerlink" title="Deploy to remote sites"></a>Deploy to remote sites</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">$ hexo deploy<br></code></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/one-command-deployment.html">Deployment</a></p>]]></content>
    
    
    
  </entry>
  
  
  
  
</search>
